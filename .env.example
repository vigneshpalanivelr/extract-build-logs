# GitLab Pipeline Log Extraction System Configuration

# ============================================================================
# REQUIRED SETTINGS
# ============================================================================

# GitLab instance URL (no trailing slash)
# Example: https://gitlab.com or https://gitlab.company.com
GITLAB_URL=https://gitlab.com

# GitLab Personal Access Token with api scope
# Create at: GitLab → Profile → Access Tokens → Select 'api' scope
GITLAB_TOKEN=your_gitlab_token_here

# Docker image name (required)
DOCKER_IMAGE_NAME=bfa-gitlab-pipeline-extractor

# Docker container name (required)
DOCKER_CONTAINER_NAME=bfa-gitlab-pipeline-extractor

# Host directory for Docker volume mount (required)
# This is the host path that gets mounted to the container
DOCKER_LOGS_DIR=./logs

# Port for webhook listener server (required)
WEBHOOK_PORT=8000

# Logging level (required)
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Directory where logs will be stored inside the container (required)
LOG_OUTPUT_DIR=./logs

# Number of retry attempts for failed API calls (required)
RETRY_ATTEMPTS=3

# Delay in seconds between retry attempts (required)
RETRY_DELAY=60


# ============================================================================
# OPTIONAL SETTINGS
# ============================================================================

# Secret token for webhook validation (recommended for production)
# This should match the secret configured in GitLab webhook settings
# Leave empty to disable validation (not recommended for production)
WEBHOOK_SECRET=

# Number of days to retain logs before cleanup
# Used by scripts/cleanup_old_logs.sh to remove old logs
# Default: 90
LOG_RETENTION_DAYS=90


# ============================================================================
# LOG FILTERING CONFIGURATION
# ============================================================================

# Which pipeline statuses to save logs for
# Options: all, failed, success, running, canceled, skipped
# Multiple values: failed,canceled,skipped
# Default: all (saves logs from all pipelines)
LOG_SAVE_PIPELINE_STATUS=failed

# Which projects to save logs for (comma-separated project IDs)
# Leave empty to save all projects
# Example: 123,456,789
# Default: (empty = all projects)
LOG_SAVE_PROJECTS=

# Which projects to exclude from logging (comma-separated project IDs)
# Only used if LOG_SAVE_PROJECTS is empty
# Example: 999,888
# Default: (empty = no exclusions)
LOG_EXCLUDE_PROJECTS=

# Which job statuses to save logs for within a pipeline
# Options: all, failed, success, canceled, skipped
# Multiple values: failed,canceled
# Default: all (saves logs from all jobs)
LOG_SAVE_JOB_STATUS=failed

# Save pipeline metadata even if no logs are saved
# Useful for tracking all pipelines even if only storing failed logs
# Options: true, false
# Default: true
LOG_SAVE_METADATA_ALWAYS=true


# ============================================================================
# API POSTING CONFIGURATION
# ============================================================================

# Enable API posting for pipeline logs (instead of or in addition to file storage)
# NOTE: When enabled, requires BFA_HOST to be set
# API endpoint is auto-constructed as: http://BFA_HOST:8000/api/analyze
# Authentication: If BFA_SECRET_KEY is set, it will be used as Bearer token (optional)
# Options: true, false
# Default: false
API_POST_ENABLED=true

# Request timeout in seconds for API calls
# Default: 30
API_POST_TIMEOUT=180

# Enable retry logic for failed API requests
# Uses the same retry configuration as GitLab API calls (RETRY_ATTEMPTS, RETRY_DELAY)
# Options: true, false
# Default: true
API_POST_RETRY_ENABLED=true

# Also save logs to files when API posting is enabled
# Options: true, false
# Default: false
# - false: API only (file storage as fallback if API fails)
# - true: Dual mode (always save to both API and files)
API_POST_SAVE_TO_FILE=false


# ============================================================================
# JENKINS INTEGRATION CONFIGURATION
# ============================================================================

# SINGLE INSTANCE vs MULTIPLE INSTANCES:
# ------------------------------------------------------------------------------
# There are two ways to configure Jenkins integration:
#
# 1. SINGLE INSTANCE (using .env file - this file):
#    - Configure the settings below for one Jenkins instance
#    - Simple setup for organizations with one Jenkins server
#    - Backward compatible with existing configurations
#
# 2. MULTIPLE INSTANCES (using jenkins_instances.json file):
#    - Support multiple Jenkins instances with different credentials
#    - Create jenkins_instances.json from jenkins_instances.json.example
#    - Each instance can have different URL, credentials, and webhook secrets
#    - Jenkinsfile must include jenkins_url in webhook payload
#    - If jenkins_instances.json exists, it takes precedence over .env
#
# See jenkins_instances.json.example and DOCUMENTATION.md for multi-instance setup
# ------------------------------------------------------------------------------

# Enable Jenkins webhook support
# Options: true, false
# Default: false
JENKINS_ENABLED=false

# Jenkins instance URL (no trailing slash)
# Required if JENKINS_ENABLED=true (for single instance setup)
# Example: https://jenkins.example.com
# Note: For multiple Jenkins instances, use jenkins_instances.json instead
JENKINS_URL=

# Jenkins username for API authentication
# Required if JENKINS_ENABLED=true (for single instance setup)
# Note: For multiple Jenkins instances, use jenkins_instances.json instead
JENKINS_USER=

# Jenkins API token for authentication
# Required if JENKINS_ENABLED=true (for single instance setup)
# Create at: Jenkins → User → Configure → API Token → Add new Token
# Note: For multiple Jenkins instances, use jenkins_instances.json instead
JENKINS_API_TOKEN=

# Secret token for Jenkins webhook validation (optional)
# This should match the token sent in X-Jenkins-Token header from Jenkinsfile
# Leave empty to disable validation
# Note: For multiple Jenkins instances, each can have its own secret in jenkins_instances.json
JENKINS_WEBHOOK_SECRET=

# Filter out handled failures from Jenkins pipeline processing
# When enabled, only reports stages that actually stopped the pipeline (real failures)
# Filters out failures that were caught with try-catch/fallback mechanisms (handled failures)
#
# How it works:
# - If a stage fails but subsequent stages execute successfully, the failure is "handled"
# - Only stages that fail with no successful stages after them are "real failures"
# - This solves the problem of Blue Ocean marking caught exceptions as failures
#
# Options: true, false
# Default: true (recommended - filters handled failures)
# Use false only if you want to see ALL failures including handled ones
JENKINS_FILTER_HANDLED_FAILURES=true


# ============================================================================
# BFA JWT TOKEN GENERATION CONFIGURATION
# ============================================================================

# BFA Host - Hostname/IP of BFA server (without http:// prefix)
# This will be used to construct the API endpoint: http://BFA_HOST:8000/api/analyze
# Example: bfa-server.example.com or 192.168.1.100
BFA_HOST=

# Secret key for BFA JWT token signing (for /api/token endpoint)
# NOTE: BFA_SECRET_KEY is completely separate from GITLAB_TOKEN
#       - BFA_SECRET_KEY: Used for signing JWT tokens for API authentication
#       - GITLAB_TOKEN: Used for authenticating with GitLab API
# REQUIRED: This must be set explicitly - no fallback to GITLAB_TOKEN
# If not set, JWT token generation will be disabled and errors will be logged
#
# How to obtain BFA_SECRET_KEY:
# Option 1: Get from BFA server
#   curl -X POST http://BFA_HOST:8000/api/token
#   Response: {"token": "<TOKEN>"}
#   Then set: BFA_SECRET_KEY=<TOKEN>
#
# Option 2: Generate manually
#   python -c "import secrets; print(secrets.token_urlsafe(32))"
BFA_SECRET_KEY=


# ============================================================================
# LOG ERROR EXTRACTION CONFIGURATION
# ============================================================================

# Number of log lines to include BEFORE each error line
# This provides context to help LLM understand what led to the error
# Default: 50
# Range: 0-1000 (higher values = more context, larger payloads)
# Example: If error is at line 500, includes lines 450-500
ERROR_CONTEXT_LINES_BEFORE=50

# Number of log lines to include AFTER each error line
# This provides context to see immediate consequences of the error
# Default: 10
# Range: 0-100
# Example: If error is at line 500, includes lines 500-510
ERROR_CONTEXT_LINES_AFTER=10


# ============================================================================
# USAGE INSTRUCTIONS
# ============================================================================
#
# 1. Copy this file to .env:
#    cp .env.example .env
#
# 2. Edit .env and set your GitLab URL and token
#
# 3. (Optional) Configure webhook secret in both .env and GitLab
#
# 4. Build and run the Docker container:
#    ./manage_container.py build
#    ./manage_container.py start
#
#    Or run directly (development):
#    python src/webhook_listener.py
#
# 5. View configuration:
#    ./manage_container.py config
#
# For more information, see README.md and OPERATIONS.md
#
# ============================================================================
