# GitLab Pipeline Log Extraction System Configuration

# ============================================================================
# REQUIRED SETTINGS
# ============================================================================

# GitLab instance URL (no trailing slash)
# Example: https://gitlab.com or https://gitlab.company.com
GITLAB_URL=https://gitlab.com

# GitLab Personal Access Token with api scope
# Create at: GitLab → Profile → Access Tokens → Select 'api' scope
GITLAB_TOKEN=your_gitlab_token_here


# ============================================================================
# OPTIONAL SETTINGS (defaults provided)
# ============================================================================

# Port for webhook listener server
# Default: 8000
WEBHOOK_PORT=8000

# Secret token for webhook validation (recommended for production)
# This should match the secret configured in GitLab webhook settings
# Leave empty to disable validation (not recommended for production)
WEBHOOK_SECRET=

# Directory where logs will be stored
# Default: ./logs
LOG_OUTPUT_DIR=./logs

# Number of retry attempts for failed API calls
# Default: 3
RETRY_ATTEMPTS=3

# Delay in seconds between retry attempts
# Default: 2
RETRY_DELAY=2

# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# Default: INFO
LOG_LEVEL=INFO


# ============================================================================
# LOG FILTERING CONFIGURATION
# ============================================================================

# Which pipeline statuses to save logs for
# Options: all, failed, success, running, canceled, skipped
# Multiple values: failed,canceled,skipped
# Default: all (saves logs from all pipelines)
LOG_SAVE_PIPELINE_STATUS=failed

# Which projects to save logs for (comma-separated project IDs)
# Leave empty to save all projects
# Example: 123,456,789
# Default: (empty = all projects)
LOG_SAVE_PROJECTS=

# Which projects to exclude from logging (comma-separated project IDs)
# Only used if LOG_SAVE_PROJECTS is empty
# Example: 999,888
# Default: (empty = no exclusions)
LOG_EXCLUDE_PROJECTS=

# Which job statuses to save logs for within a pipeline
# Options: all, failed, success, canceled, skipped
# Multiple values: failed,canceled
# Default: all (saves logs from all jobs)
LOG_SAVE_JOB_STATUS=all

# Save pipeline metadata even if no logs are saved
# Useful for tracking all pipelines even if only storing failed logs
# Options: true, false
# Default: true
LOG_SAVE_METADATA_ALWAYS=true


# ============================================================================
# API POSTING CONFIGURATION
# ============================================================================

# Enable API posting for pipeline logs (instead of or in addition to file storage)
# NOTE: When enabled, requires BFA_HOST and BFA_SECRET_KEY to be set
# API endpoint is auto-constructed as: http://BFA_HOST:8000/api/analyze
# Authentication uses BFA_SECRET_KEY as Bearer token
# Options: true, false
# Default: false
API_POST_ENABLED=false

# Request timeout in seconds for API calls
# Default: 30
API_POST_TIMEOUT=30

# Enable retry logic for failed API requests
# Uses the same retry configuration as GitLab API calls (RETRY_ATTEMPTS, RETRY_DELAY)
# Options: true, false
# Default: true
API_POST_RETRY_ENABLED=true

# Also save logs to files when API posting is enabled
# Options: true, false
# Default: false
# - false: API only (file storage as fallback if API fails)
# - true: Dual mode (always save to both API and files)
API_POST_SAVE_TO_FILE=false


# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# Database URL for PostgreSQL (optional, uses SQLite by default)
# If set, the system will use PostgreSQL instead of SQLite
# Format: postgresql://username:password@host:port/database
# Example: postgresql://logextractor:password@localhost:5432/pipeline_logs
# Leave empty to use SQLite (default: ./logs/monitoring.db)
DATABASE_URL=

# Note: SQLite is sufficient for most use cases (handles 50-100 writes/sec)
# Use PostgreSQL when:
# - You need multiple service instances sharing one database
# - You're seeing "database is locked" errors frequently
# - You have very high webhook volume (>100/minute)


# ============================================================================
# JENKINS INTEGRATION CONFIGURATION
# ============================================================================

# Enable Jenkins webhook support
# Options: true, false
# Default: false
JENKINS_ENABLED=false

# Jenkins instance URL (no trailing slash)
# Required if JENKINS_ENABLED=true
# Example: https://jenkins.example.com
JENKINS_URL=

# Jenkins username for API authentication
# Required if JENKINS_ENABLED=true
JENKINS_USER=

# Jenkins API token for authentication
# Required if JENKINS_ENABLED=true
# Create at: Jenkins → User → Configure → API Token → Add new Token
JENKINS_API_TOKEN=

# Secret token for Jenkins webhook validation (optional)
# This should match the token sent in X-Jenkins-Token header from Jenkinsfile
# Leave empty to disable validation
JENKINS_WEBHOOK_SECRET=


# ============================================================================
# BFA JWT TOKEN GENERATION CONFIGURATION
# ============================================================================

# BFA Host - Hostname/IP of BFA server (without http:// prefix)
# This will be used to construct the API endpoint: http://BFA_HOST:8000/api/analyze
# Example: bfa-server.example.com or 192.168.1.100
BFA_HOST=

# Secret key for BFA JWT token signing (for /api/token endpoint)
# NOTE: BFA_SECRET_KEY is completely separate from GITLAB_TOKEN
#       - BFA_SECRET_KEY: Used for signing JWT tokens for API authentication
#       - GITLAB_TOKEN: Used for authenticating with GitLab API
# REQUIRED: This must be set explicitly - no fallback to GITLAB_TOKEN
# If not set, JWT token generation will be disabled and errors will be logged
#
# How to obtain BFA_SECRET_KEY:
# Option 1: Get from BFA server
#   curl -X POST http://BFA_HOST:8000/api/token
#   Response: {"token": "<TOKEN>"}
#   Then set: BFA_SECRET_KEY=<TOKEN>
#
# Option 2: Generate manually
#   python -c "import secrets; print(secrets.token_urlsafe(32))"
BFA_SECRET_KEY=


# ============================================================================
# EMAIL NOTIFICATION CONFIGURATION
# ============================================================================

# Enable email notifications for API response processing
# Options: true, false
# Default: false
EMAIL_NOTIFICATIONS_ENABLED=false

# SMTP server hostname (uses server's local SMTP relay)
# Default: localhost
SMTP_HOST=localhost

# SMTP server port
# Default: 25 (standard SMTP), use 587 for TLS
SMTP_PORT=25

# Email address to send notifications from
# Required if EMAIL_NOTIFICATIONS_ENABLED=true
# Example: pipeline-logs@company.com
SMTP_FROM_EMAIL=

# DevOps team email address for failure notifications
# Required if EMAIL_NOTIFICATIONS_ENABLED=true
# When API posting fails (status != 200), alert is sent to this address
# Example: devops-team@company.com
DEVOPS_EMAIL=


# ============================================================================
# USAGE INSTRUCTIONS
# ============================================================================
#
# 1. Copy this file to .env:
#    cp .env.example .env
#
# 2. Edit .env and set your GitLab URL and token
#
# 3. (Optional) Configure webhook secret in both .env and GitLab
#
# 4. Build and run the Docker container:
#    ./manage_container.py build
#    ./manage_container.py start
#
#    Or run directly (development):
#    python src/webhook_listener.py
#
# 5. View configuration:
#    ./manage_container.py config
#
# For more information, see README.md and OPERATIONS.md
#
# ============================================================================
